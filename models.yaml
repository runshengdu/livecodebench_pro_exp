# LLM Model Configuration
# This file defines available language models and their configurations
#
# Configuration Options:
#   - name: Model identifier
#   - temperature: Sampling temperature (0.0 = deterministic, 1.0 = creative)
#   - base_url: API endpoint URL
#   - api_key: API key (can reference environment variables with ${VAR_NAME})
#   - max_tokens: Maximum tokens in the response (optional, default: 8192)
#   - extra_body: Additional parameters passed to the API (model-specific)
#
# Recommended max_tokens values by model type:
#   - Standard models (GPT, Claude, Gemini): 8192-16384
#   - Reasoning models (DeepSeek Reasoner, GLM thinking): 32768-65536
#   - Mini models: 4096-8192
#
# Note: If max_tokens is not specified, the API's default limit will be used,
# which may cause truncation for long code outputs.

# Available models
models:
  - name: openai/gpt-5.2
    temperature: 1.0
    base_url: https://openrouter.ai/api/v1
    api_key: "${OPENROUTER_API_KEY}"
    extra_body: {"reasoning": {"effort": "high"}}
    max_tokens: 128000

  - name: openai/gpt-5-mini
    temperature: 0.0
    base_url: https://openrouter.ai/api/v1
    api_key: "${OPENROUTER_API_KEY}"
    extra_body: {"reasoning": {"effort": "minimal"}}
    max_tokens: 16384
  
  - name: x-ai/grok-4.1-fast
    temperature: 0.0
    base_url: https://openrouter.ai/api/v1
    api_key: "${OPENROUTER_API_KEY}"
    extra_body:
      reasoning:
        enabled: false
    max_tokens: 32768


  - name: anthropic/claude-sonnet-4.5
    temperature: 1.0
    base_url: https://openrouter.ai/api/v1
    api_key: "${OPENROUTER_API_KEY}"
    extra_body: {"reasoning": {"effort": "high"}}
    max_tokens: 200000


  - name: google/gemini-3-pro-preview
    temperature: 1.0
    base_url: https://openrouter.ai/api/v1
    api_key: "${OPENROUTER_API_KEY}"
    max_tokens: 1048576

  
  - name: google/gemini-3-flash-preview
    temperature: 1.0
    base_url: https://openrouter.ai/api/v1
    api_key: "${OPENROUTER_API_KEY}"
    extra_body: {"reasoning": {"effort": "high"}}
    max_tokens: 131072


  - name: minimax-m2
    temperature: 1.0
    base_url: https://api.minimaxi.com/v1
    api_key: "${MINIMAX_API_KEY}"
    max_tokens: 8192


  - name: minimax-m2.1
    temperature: 1.0
    base_url: https://api.minimaxi.com/v1
    api_key: "${MINIMAX_API_KEY}"
    max_tokens: 8192


  - name: deepseek-chat
    temperature: 0.0
    base_url: https://api.deepseek.com
    api_key: "${DEEPSEEK_API_KEY}"
    max_tokens: 8192


  - name: deepseek-reasoner
    temperature: 1.0
    base_url: https://api.deepseek.com
    api_key: "${DEEPSEEK_API_KEY}"
    max_tokens: 65536

  
  - name: glm-4.6
    temperature: 1.0
    base_url: https://open.bigmodel.cn/api/paas/v4
    api_key: "${GLM_API_KEY}"
    extra_body: {"thinking": {"type": "enabled"}}
    max_tokens: 131072
    #turn it off for evaluation

  - name: glm-4.7
    temperature: 1.0
    base_url: https://open.bigmodel.cn/api/paas/v4
    api_key: "${GLM_API_KEY}"
    extra_body: {"thinking": {"type": "enabled"}}
    max_tokens: 131072

  - name: kimi-k2-thinking
    temperature: 1.0
    base_url: https://api.moonshot.cn/v1
    api_key: "${MOONSHOT_API_KEY}"
    max_tokens: 16384

  
  - name: kimi-k2-0905-preview
    temperature: 0.0
    base_url: https://api.moonshot.cn/v1
    api_key: "${MOONSHOT_API_KEY}"
    max_tokens: 8192
  
  - name: doubao-seed-1-8-251228
    temperature: 1.0
    base_url: https://ark.cn-beijing.volces.com/api/v3
    api_key: "${ARK_API_KEY}"
    extra_body: {"reasoning_effort": "high"}
    max_tokens: 32768
